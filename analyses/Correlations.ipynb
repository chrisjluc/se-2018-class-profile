{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file contains all of the correlations that we want to calculate. This means that we need at least 2 columns to create a result.\n",
    "\n",
    "Most of these correlations have to do with coop salary, or term average. We use these as metrics of student success because they're numeric, making them easier to process. Other properties are very subjective. Salary and grades are not the most indicative of how successful a student is, but with the existing data, it's the best indication we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "from Bucket import Bucket\n",
    "from Distribution import Distribution\n",
    "from GradeSalaryHistory import GradeSalaryHistory\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "# Show matplotlib plots in this notebook\n",
    "%matplotlib inline\n",
    "# Setting plot parameters\n",
    "from pylab import rcParams\n",
    "params = {\n",
    "    'figure.figsize': (8, 8),\n",
    "    'legend.fontsize': 15\n",
    "}\n",
    "rcParams.update(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isnan(a):\n",
    "    return a != a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isempty(a):\n",
    "    return isnan(a) or not a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isfloat(value):\n",
    "  try:\n",
    "    float(value)\n",
    "    return not isnan(value)\n",
    "  except ValueError:\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Where to write the buckets\n",
    "BUCKET_DIR = '../private/buckets/'\n",
    "GRADE_SALARY_FILENAME = '../private/grade-vs-salary.json'\n",
    "df = pd.read_csv('../private/results-04-10.csv')  # TODO: Write the response file\n",
    "\n",
    "COOP = ['1', '2', '3', '4', '5', '6']\n",
    "TERM = ['1a', '1b', '2a', '2b', '3a', '3b', '4a']\n",
    "MULTI_VAL_COL = ['ethnicity', 'fav_lang', 'preferred_tech_discipline', 'text_editor']\n",
    "\n",
    "SALARY_COL = ['coop_salary_' + i + '.csv' for i in COOP]\n",
    "GRADE_COL = ['term_avg_' + i + '.csv' for i in TERM]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_buckets(df, col_name):\n",
    "    \"\"\"Creates a bucket for each value and then writes the values into a file.\"\"\"\n",
    "    buckets = correlate_columns(df, col_name)\n",
    "    with open(BUCKET_DIR + col_name + '_buckets.json', 'w') as f:\n",
    "        result = {}\n",
    "        for i in buckets:\n",
    "            result[i] = buckets[i].summary()\n",
    "        f.write(json.dumps(result, indent=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlate_columns(df, col_name):\n",
    "\n",
    "    \"\"\"Generates a bucket for unique column value.\"\"\"\n",
    "    # Get unique values (some rows have multiple values)\n",
    "    col_values = np.array([])\n",
    "    for i in df[col_name]:\n",
    "        if isfloat(i):\n",
    "            # Floor any data\n",
    "            i = math.floor(float(i))\n",
    "        if isnan(i):\n",
    "            # Don't want to include any NaN\n",
    "            print('Skipping ', i)\n",
    "            continue\n",
    "            \n",
    "        # Append separate values if it's a comma separated value\n",
    "        val = str(i)\n",
    "        if ',' in val and col_name in MULTI_VAL_COL:\n",
    "            col_values = np.append(col_values, list(map(str.strip, val.split(','))))\n",
    "        else:\n",
    "            col_values = np.append(col_values, val)\n",
    "            \n",
    "    col_values = np.unique(col_values)\n",
    "    # Create a bucket for each column value\n",
    "    buckets = {}\n",
    "    for col_val in col_values:\n",
    "        # Initialize distributions\n",
    "        salaries = {}\n",
    "        grades = {}\n",
    "        for i in TERM:\n",
    "            grades[i] = np.array([])\n",
    "        for i in COOP:\n",
    "            salaries[i] = np.array([])\n",
    "        \n",
    "        # Iterate through all rows\n",
    "        for i in range(0, df.shape[0]):\n",
    "            val = df[col_name][i]\n",
    "            if isfloat(val):\n",
    "                val = math.floor(float(val))\n",
    "            \n",
    "            # Filter any NaN or non matching values\n",
    "            if isnan(val):\n",
    "                continue\n",
    "            if col_name in MULTI_VAL_COL:\n",
    "                if str(col_val) not in map(str.strip, str(val).split(',')):\n",
    "                    continue\n",
    "            else:\n",
    "                if str(col_val) != str(val):\n",
    "                    continue\n",
    "                \n",
    "            # Add grades\n",
    "            for t in TERM:\n",
    "                avg = df['term_avg_' + t][i]\n",
    "                if avg == 'exchange':\n",
    "                    continue\n",
    "                if isnan(avg):\n",
    "                    continue\n",
    "                grades[t] = np.append(grades[t], avg)\n",
    "            \n",
    "            # Add salary\n",
    "            for c in COOP:\n",
    "                salary = df['coop_salary_' + c][i]\n",
    "                if type(salary) == float and math.isnan(salary):\n",
    "                    continue\n",
    "                if ',' in salary:\n",
    "                    salary = salary.replace(',', '')\n",
    "                salaries[c] = np.append(salaries[c], salary)\n",
    "\n",
    "        # Create the bucket\n",
    "        buckets[col_val] = Bucket(col_name, col_val, \n",
    "                   [Distribution(grades[i].astype(float)) for i in TERM],\n",
    "                   [Distribution(salaries[i].astype(float)) for i in COOP])\n",
    "    \n",
    "    return buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Skipping ', nan)\n",
      "('Skipping ', nan)\n",
      "('Skipping ', nan)\n",
      "('Skipping ', nan)\n",
      "('Skipping ', nan)\n",
      "('Skipping ', nan)\n"
     ]
    }
   ],
   "source": [
    "# From https://github.com/se2018/class-profile/tree/master/analyses\n",
    "to_correlate = [\n",
    "    'gender',\n",
    "    'ethnicity',\n",
    "    'family_income',\n",
    "    'work_os',\n",
    "    'phone',\n",
    "    'soft_eng_rating',\n",
    "    'se_friendships',\n",
    "    'is_international',\n",
    "    'parents_edu',\n",
    "    'parents_technical',\n",
    "    'admission_avg',\n",
    "    'code_start_age',\n",
    "    'fav_lang',\n",
    "    'num_hackathons',\n",
    "    'side_proj',\n",
    "    'exercise',\n",
    "    'cooking',\n",
    "    'sleep_time',\n",
    "    'preferred_tech_discipline',\n",
    "    'text_editor'\n",
    "]\n",
    "\n",
    "for i in to_correlate:\n",
    "    write_buckets(df, i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next section is to get the correlation between grades and coop jobs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_history(df):\n",
    "    \"\"\"Creates an entry for each coop term about the grades and salaries leading up to it.\"\"\"\n",
    "    result = {}\n",
    "    for i, term in enumerate(COOP):\n",
    "        result[term] = defaultdict(list)\n",
    "        \n",
    "        for row in range(0, df.shape[0]):\n",
    "            # Skip any entries that are missing data on the coop\n",
    "            if isempty(df['coop_name_' + term][row]) or isempty(df['coop_salary_' + term][row]):\n",
    "                print 'Empty term for row ', row, ', term ', term, 'skipping entry.'\n",
    "                continue\n",
    "                \n",
    "            # Process a coop term\n",
    "            term_avgs = np.array([])\n",
    "            salaries = np.array([])\n",
    "            \n",
    "            # Get previous grades\n",
    "            for study in range(0, i+1):\n",
    "                val = df['term_avg_' + str(TERM[study])][row]\n",
    "                if isnan(val) or val == 'exchange':\n",
    "                    term_avgs = np.append(term_avgs, 0.0)\n",
    "                else:\n",
    "                    term_avgs = np.append(term_avgs, math.floor(float(val)))\n",
    "            \n",
    "            # Get previous salaries\n",
    "            for coop in range(0, i):\n",
    "                val = str(df['coop_salary_' + COOP[coop]][row])\n",
    "                val = val.replace(',', '')\n",
    "                if isnan(float(val)):\n",
    "                    salaries = np.append(salaries, 0)\n",
    "                else:\n",
    "                    salaries = np.append(salaries, float((int(float(val)) / 500 * 500)))\n",
    "            \n",
    "            location = df['coop_loc_' + term][row]\n",
    "            if isempty(location):\n",
    "                location = ''\n",
    "            salary = df['coop_salary_' + term][row]\n",
    "            # Estimate to the nearest 500*i\n",
    "            salary = float(int(float(str(salary).replace(',', ''))) / 500 * 500)\n",
    "            \n",
    "            result[term][str(salary)].append(GradeSalaryHistory(term_avgs, salaries, location, salary).summary())\n",
    "    \n",
    "    return result\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty term for row  5 , term  1 skipping entry.\n",
      "Empty term for row  30 , term  1 skipping entry.\n",
      "Empty term for row  45 , term  1 skipping entry.\n",
      "Empty term for row  55 , term  1 skipping entry.\n",
      "Empty term for row  60 , term  1 skipping entry.\n",
      "Empty term for row  67 , term  1 skipping entry.\n",
      "Empty term for row  93 , term  1 skipping entry.\n",
      "Empty term for row  7 , term  2 skipping entry.\n",
      "Empty term for row  45 , term  2 skipping entry.\n",
      "Empty term for row  64 , term  2 skipping entry.\n",
      "Empty term for row  82 , term  3 skipping entry.\n",
      "Empty term for row  91 , term  3 skipping entry.\n",
      "Empty term for row  100 , term  3 skipping entry.\n",
      "Empty term for row  8 , term  4 skipping entry.\n",
      "Empty term for row  73 , term  4 skipping entry.\n",
      "Empty term for row  107 , term  4 skipping entry.\n",
      "Empty term for row  112 , term  4 skipping entry.\n",
      "Empty term for row  26 , term  5 skipping entry.\n",
      "Empty term for row  77 , term  5 skipping entry.\n",
      "Empty term for row  86 , term  5 skipping entry.\n",
      "Empty term for row  58 , term  6 skipping entry.\n",
      "Empty term for row  64 , term  6 skipping entry.\n",
      "Empty term for row  74 , term  6 skipping entry.\n",
      "Empty term for row  87 , term  6 skipping entry.\n"
     ]
    }
   ],
   "source": [
    "with open(GRADE_SALARY_FILENAME, 'w') as f:\n",
    "    f.write(json.dumps(create_history(df), indent=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
