{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About this file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file takes all of the files that have been normalized, and writes them in a new `responses-{date}.csv` file. Since the results file is not saved in version control, it will create a different response file each day. Again, this is only because we don't want to commit private data into version control.\n",
    "\n",
    "To ensure that data never gets lost, we can also maintan this git project inside of a Dropbox/Drive. This is to prevent loss of any work in case the files get accidentally deleted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import random\n",
    "import json\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "import constants\n",
    "\n",
    "# Configure any settings\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare any constants\n",
    "raw_file = '../data/raw.csv' # REPLACE THIS WITH THE MOST EXISTING DATA SET FILEPATH\n",
    "results_directory = '../private/' # Path where we'll create the data set with the normalized columns\n",
    "normalized_rows_directory = '../private/normalized_rows/' # Path with the normalized rows\n",
    "indices_directory = '../private/indices/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(raw_file)\n",
    "df.columns = constants.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grabs the metadata file given a filename, and returns the shuffled indices\n",
    "def read_indices(filename):\n",
    "    with open(indices_directory + filename, 'r') as f:\n",
    "        metadata = json.loads(f.read())\n",
    "        return metadata['order']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns a list of all of the rows values\n",
    "def read_normalized_rows(filename):\n",
    "    if not os.path.isfile(normalized_rows_directory + filename):\n",
    "        return None\n",
    "    df = pd.read_csv(normalized_rows_directory + filename)\n",
    "    return df[df.columns[1]].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Place each row into its original location\n",
    "def unshuffle_rows(rows, indices):\n",
    "    buffer = [None] * len(indices)\n",
    "    for i, index in enumerate(indices):\n",
    "        buffer[i] = rows[index]\n",
    "    return buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "row_count = df.shape[0]\n",
    "\n",
    "for col in constants.columns_to_normalize:\n",
    "    # Read the normalized rows\n",
    "    rows_filename = col + '.csv'\n",
    "    normalized_rows = read_normalized_rows(rows_filename)\n",
    "\n",
    "    # File doesn't exist\n",
    "    if normalized_rows is None:\n",
    "        continue\n",
    "    \n",
    "    # Read the private indices\n",
    "    indices_filename = col + '.json'\n",
    "    indices = read_indices(indices_filename)\n",
    "    \n",
    "    # Unshuffle the rows\n",
    "    column_data = unshuffle_rows(normalized_rows, indices)\n",
    "    \n",
    "    # Save it inside the dataframe\n",
    "    df[col] = column_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.datetime.now()\n",
    "formatted_date = now.strftime(\"%m-%d\")\n",
    "df.to_csv(results_directory + 'results-' + formatted_date + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
